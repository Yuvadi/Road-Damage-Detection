{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
    "!/usr/local/cuda/bin/nvcc --version\n",
    "# We need to install the correct cuDNN according to this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the kind of GPU we have\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell ensures you have the correct architecture for your respective GPU\n",
    "# If you command is not found, look through these GPUs, find the respective\n",
    "# GPU and add them to the archTypes dictionary\n",
    "\n",
    "# Tesla V100\n",
    "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
    "\n",
    "# Tesla K80 \n",
    "# ARCH= -gencode arch=compute_37,code=sm_37\n",
    "\n",
    "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
    "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
    "\n",
    "# Jetson XAVIER\n",
    "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
    "\n",
    "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
    "# ARCH= -gencode arch=compute_61,code=sm_61\n",
    "\n",
    "# GP100/Tesla P100 - DGX-1\n",
    "# ARCH= -gencode arch=compute_60,code=sm_60\n",
    "\n",
    "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
    "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
    "\n",
    "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
    "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
    "import os\n",
    "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
    "\n",
    "def getGPUArch(argument):\n",
    "  try:\n",
    "    argument = argument.strip()\n",
    "    # All Colab GPUs\n",
    "    archTypes = {\n",
    "        \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
    "        \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
    "        \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
    "        \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
    "        \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
    "        \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
    "\n",
    "      }\n",
    "    return archTypes[argument]\n",
    "  except KeyError:\n",
    "    return \"GPU must be added to GPU Commands\"\n",
    "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
    "\n",
    "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
    "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
